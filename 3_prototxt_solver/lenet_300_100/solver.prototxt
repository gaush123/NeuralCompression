# The train/test net protocol buffer definition
net: "3_prototxt_solver/lenet_300_100/train_val.prototxt"
# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
test_iter: 100
# Carry out testing every 500 training iterations.
test_interval: 500
# solver type
# solver_type: SGD
#solver_type: NAG
#solver_type: ADAGRAD
# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.05
momentum: 0.9
weight_decay: 0.00002
# The learning rate policy
#- fixed: always return base_lr.
#- step: return base_lr * gamma ^ (floor(iter / step))
#- exp: return base_lr * gamma ^ iter
#- inv: return base_lr * (1 + gamma * iter) ^ (- power)
#- multistep: similar to step but it allows non uniform steps defined by
#  stepvalue
#- poly: the effective learning rate follows a polynomial decay, to be
#  zero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)
#- sigmoid: the effective learning rate follows a sigmod decay
#  return base_lr ( 1/(1 + exp(-gamma * (iter - stepsize))))
lr_policy: "inv"
gamma: 0.0001
power: 0.75
# Display every 100 iterations
display: 100
# The maximum number of iterations
max_iter: 20000
# snapshot intermediate results
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet_300_100/lenet_300_100"
# solver mode: CPU or GPU
solver_mode: GPU
solver_type: NESTEROV